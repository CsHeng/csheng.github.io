<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Writing Bugs</title>
    <link>https://sukikaka.cc/posts/</link>
    <description>Recent content in Posts on Writing Bugs</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 13 May 2021 16:26:21 +0800</lastBuildDate><atom:link href="https://sukikaka.cc/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>机房托管的血与泪</title>
      <link>https://sukikaka.cc/2021/05/13/%E6%9C%BA%E6%88%BF%E6%89%98%E7%AE%A1%E7%9A%84%E8%A1%80%E4%B8%8E%E6%B3%AA/</link>
      <pubDate>Thu, 13 May 2021 16:26:21 +0800</pubDate>
      
      <guid>https://sukikaka.cc/2021/05/13/%E6%9C%BA%E6%88%BF%E6%89%98%E7%AE%A1%E7%9A%84%E8%A1%80%E4%B8%8E%E6%B3%AA/</guid>
      <description>前言  为了解决日益增长的计算、存储、测试环境的需求，结合我们办公室小机房优异的散热、电量、网络条件(详情如下)，因此在2021年3月份决定将公司的13台Dell R720服务器搬迁到机房进行托管，以期获得稳定的使用条件。
  散热：开了16度然而还能热出汗的空调 供电：预期下午5点断电早上11点先尝试性进行预演 机房布线管理：网线乱飞、电源线乱飞、随时踩一脚断电or断网 潘多拉的域名玩法：电信专线并不封堵TCP/443，当年（2017）使用TCP/443并配合DNS-01 challenge验证域名所有权，然后使用Let&#39;s Encrypt来签发证书，最终提供给测试环境HTTPS证书，并且在公网环境提供免备案的服务  极其漫长的踩坑之路  从3月初决定要搞事，一遍采购新机器到最终上架“萝岗加速器”机房的时间是5月7号，整整两个月。
 硬件玄学  二手硬件不稳定什么的，对于我们这种垃圾佬当然不是什么问题啦！插电，开机~~~
  服务器采购（花费一周）  购买6台新的Dell R720 XD 2U服务器，每台机器配置  CPU： E5 2650V2 * 2 H710P mini 硬盘阵列卡 内存：8GB/16GB * 16 = 144GB/288GB     迁移原有服务器(Dell R420)内硬盘到新的机器  顺利的：基本直接开机，硬件自检通过，重新配置阵列卡，开机完成硬件升级 失败的：硬盘阵列卡故障、硬盘背板失败不通电、内存没装好&amp;hellip;..    PVE集群之坑   原有用于测试环境的3台1U服务器，升级成4台2U的服务器（由于IP经过了变更，所以需要重新组件集群而不是使用现有的集群）
 旧的集群：2台1U服务器原本已经安装了PVE并且有虚拟机提供测试环境数据，正在服役 新的集群：2台新机器直接安装PVE操作系统，组建集群    集群管理的坑
 对pve集群node节点管理不熟悉  官方文档是最好的解决方案   对pve虚拟机磁盘管理不熟悉导致的坑  误删两个虚拟机硬盘，直接导致测试环境需要重建 remove/purge的时候要认真阅读警告信息。。。      域名备案问题  这是个迷之问题，只有在神奇的东方才有这种需求，这个过程花了一些时间去了解政策才算是明确了再次备案不影响原先接入备案的问题。</description>
    </item>
    
    <item>
      <title>通过 DHCP Options 下发路由解决同局域网内服务器互访的效率问题</title>
      <link>https://sukikaka.cc/2021/01/19/%E9%80%9A%E8%BF%87-dhcp-options-%E4%B8%8B%E5%8F%91%E8%B7%AF%E7%94%B1%E8%A7%A3%E5%86%B3%E5%90%8C%E5%B1%80%E5%9F%9F%E7%BD%91%E5%86%85%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BA%92%E8%AE%BF%E7%9A%84%E6%95%88%E7%8E%87%E9%97%AE%E9%A2%98/</link>
      <pubDate>Tue, 19 Jan 2021 11:27:19 +0800</pubDate>
      
      <guid>https://sukikaka.cc/2021/01/19/%E9%80%9A%E8%BF%87-dhcp-options-%E4%B8%8B%E5%8F%91%E8%B7%AF%E7%94%B1%E8%A7%A3%E5%86%B3%E5%90%8C%E5%B1%80%E5%9F%9F%E7%BD%91%E5%86%85%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BA%92%E8%AE%BF%E7%9A%84%E6%95%88%E7%8E%87%E9%97%AE%E9%A2%98/</guid>
      <description>背景  局域网 Kubernetes 测试服务器的具有公网(1.2.3.4)、局域网(10.0.0.10)双网卡 日常需求较多需要从局域网内/公网环境通过域名访问测试服务器（同时还有部分正式环境的大数据服务）  旧方案  公网环境 DNS 配置gw.sukikaka.com A 1.2.3.4 局域网环境 DNS Server 10.0.0.1 配置劫持成 gw.sukikaka.com A 10.0.0.10 局域网环境通过 DHCP Server 配置 DHCP Options 6,10.0.0.1,223.5.5.5 来达到下发 DNS Server 的目的 而以前用内网DNS服务器添加劫持，将gw.sukikaka.com A 10.0.0.10从而解决解析的问题，但是其他测试环境域名通过CNAME将解析指向gw.sukikaka.com时，并不能将CNAME再次顺利解析到10.0.0.10   存在的问题
 需要将DNS Server设置成内网指定的DNS Server 10.0.0.10，否则无法劫持 增减域名需要在公网DNS Server设置解析，也需要在局域网DNS Server设置解析 另外，由于公司不少同事是使用科学上网，而这些科学上网很难要求他们会自己将DNS Server设置成内网的Server，所以最终导致占用 Kubernetes 公网带宽，测试环境体验不好  访问测试环境的数据会经过主路由器 NAT 成 default route 的公网地址，然后再访问Kubernetes的公网地址NAT回来，然后处理完成之后再反向回来局域网内的请求客户端，ip packet 增加了多余的NAT     新方案  公网环境 DNS 配置gw.sukikaka.com A 1.</description>
    </item>
    
    <item>
      <title>Migrate to Hugo</title>
      <link>https://sukikaka.cc/2020/08/18/migrate-to-hugo/</link>
      <pubDate>Tue, 18 Aug 2020 16:23:18 +0800</pubDate>
      
      <guid>https://sukikaka.cc/2020/08/18/migrate-to-hugo/</guid>
      <description>2017年搭建的hexo博客，因腾讯云学生机即将过期，这几年用下来也觉得：似乎没什么必要续费云服务器
另外，人老了对npm这种一大坨恶心东西没什么好感，因此决定换用hugo，以此记录。
 hexo迁移到hugo 腾讯云迁移到github pages 启用disqus评论  UPDATE 2020-09-10  由于实在忍受不了github pages速度。。。。
 于是：
 又迁移到了腾讯云对象存储+CDN+免费HTTPS证书，按访问量收费，估计就。。。几块钱一个月吧，可以忽略不计- -# 使用腾讯云对象存储coscmd工具上传public文件夹，和之前github pages上传到github一样，也问题不大。。  </description>
    </item>
    
    <item>
      <title>Vue项目使用Nginx部署并发布到子目录</title>
      <link>https://sukikaka.cc/2019/07/11/vue%E9%A1%B9%E7%9B%AE%E4%BD%BF%E7%94%A8nginx%E9%83%A8%E7%BD%B2%E5%B9%B6%E5%8F%91%E5%B8%83%E5%88%B0%E5%AD%90%E7%9B%AE%E5%BD%95/</link>
      <pubDate>Thu, 11 Jul 2019 15:56:06 +0000</pubDate>
      
      <guid>https://sukikaka.cc/2019/07/11/vue%E9%A1%B9%E7%9B%AE%E4%BD%BF%E7%94%A8nginx%E9%83%A8%E7%BD%B2%E5%B9%B6%E5%8F%91%E5%B8%83%E5%88%B0%E5%AD%90%E7%9B%AE%E5%BD%95/</guid>
      <description>Vue项目使用Nginx部署并发布到子目录 默认Vue项目是以根目录来发布的，但是我们要有时候希望以子目录来做发布，那么就需要做一些修改，Vue项目本身的配置，包括Nginx也需要做一些配置修改。
对Vue项目源码的修改  以下路径以vue-cli常见项目的文件结构来说明。
   修改路由：router/index.js，添加base部分的代码。
1 2 3 4 5 6 7 8 9 10  function getAbsolutePath () { let path = location.pathname return path.substring(0, path.lastIndexOf(&amp;#39;/&amp;#39;) + 1) } export default new Router({ mode: &amp;#39;hash&amp;#39;, base: getAbsolutePath(), routes: [...] })     修改配置：config/index.js 文件，对于打包路径的定义，只处理build，将assetsPublicPath: &#39;/&#39;修改为assetsPublicPath: &#39;./&#39;
1 2 3 4 5 6 7 8 9 10 11 12 13  module.exports = { build: { // Template for index.</description>
    </item>
    
    <item>
      <title>记一次celery worker hang debug</title>
      <link>https://sukikaka.cc/2019/07/09/%E8%AE%B0%E4%B8%80%E6%AC%A1celery-worker-hang-debug/</link>
      <pubDate>Tue, 09 Jul 2019 16:00:22 +0000</pubDate>
      
      <guid>https://sukikaka.cc/2019/07/09/%E8%AE%B0%E4%B8%80%E6%AC%A1celery-worker-hang-debug/</guid>
      <description>记一次celery worker hang debug  【写在前面】： 本文最终并没有debug出为什么卡住，虽然换了种方案解决了问题。
 引入celery是为了调用京东api来做发货行为，以便提供给电商业务下快递单，然而在这个过程中，踩了一些坑（此文大概是2018年底的记录）
最初的配置，使用supervisor来管理celery进程，并且在代码更新之后，使用supervisorctl restart {$APP_NAME}来更新代码（celery并不支持gracefully reload，也暂时没有用其他更优雅的方案，待更深入的测试）
发现问题 线上的celery总是一段时间之后，就没有接受新的请求，celery beat还在发消息，python代码也在发消息存到broker(redis)里面，但消息一直没被消费
debug过程  找出celery worker的pid，  www-data 6329 0.0 0.6 157228 50640 ? S 2018 0:03 /home/ubuntu/.pyenv/versions/3.7.1/envs/ems-admin-api/bin/python /home/ubuntu/.pyenv/versions/ems-admin-api/bin/celery -A settings beat -s /tmp/celerybeat-schedule --pidfile= -l info www-data 10004 0.1 0.6 162456 53804 ? S Jan02 4:12 /home/ubuntu/.pyenv/versions/3.7.1/envs/ems-admin-api/bin/python /home/ubuntu/.pyenv/versions/ems-admin-api/bin/celery -A settings worker --autoscale=8,4 -l info www-data 18317 0.0 0.6 173032 56280 ? S Jan03 0:04 /home/ubuntu/.pyenv/versions/3.7.1/envs/ems-admin-api/bin/python /home/ubuntu/.</description>
    </item>
    
    <item>
      <title>pipenv使用指南</title>
      <link>https://sukikaka.cc/2019/05/10/pipenv%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</link>
      <pubDate>Fri, 10 May 2019 16:00:22 +0000</pubDate>
      
      <guid>https://sukikaka.cc/2019/05/10/pipenv%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</guid>
      <description>pipenv使用指南 厌倦了使用virtualenv pyenv的时候，总是先要创建一个虚拟环境，然后激活虚拟环境再写代码
有时候就单纯想要写点scripts，那么pipenv这个开箱即用的虚拟环境显然更适合
确保当期不在任何虚拟环境中，或者说在系统的解释器中 pip install pipenv
然后其他安装命令，以pipenv代替pip
比如pipenv install -r requirements.txt会将pip的依赖文件requirements.txt转换成pipenv的版本管理格式文件Pipfile和Pipfile.lock
如果是空项目，那么直接pipenv install {third-party-lib}
默认将会为你创建当前目录加随机字母组成的虚拟环境，后续直接管理
位于 ~/.local/share/virtualenvs/{pwd_basename}-{random_stuff}
如果需要在vscode中支持pipenv的话，新增支持pipenv的虚拟目录位置
 然后就可以愉快地选择pipenv的虚拟环境了</description>
    </item>
    
    <item>
      <title>pyenv使用指南</title>
      <link>https://sukikaka.cc/2018/12/28/pyenv%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</link>
      <pubDate>Fri, 28 Dec 2018 16:10:47 +0000</pubDate>
      
      <guid>https://sukikaka.cc/2018/12/28/pyenv%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</guid>
      <description>背景 之前使用venv，大部分情况下并没有什么不好，配合virtualenvwrapper，用起来倒也顺手，如果没有Python版本切换需求的话。
日常开发机器使用的python是最新版，logging的时候，使用了f&amp;rsquo;i am a {var}&amp;lsquo;这种format语法，而这个特性是Python 3.6之后才有的，于是上线之后凉凉= = （生产环境的机器是Ubuntu 16.04，仅使用apt管理Python版本，于是装的版本实际上是3.5.2）
既然吃了一回亏，那么就赶紧解决问题。。。
 题外话：貌似在Python的benchmark中，3.5、3.6、3.7中性能最差也是3.5，于是，抽空将生产机器改成用pyenv来管理版本
 食用步骤  参考pyenv-installer进行安装和配置 直接装需要的Python版本啦，比如pyenv install 3.7.1 如果安装过程中有任何问题，参考common build problems 如果安装也成功了，那么希望更改当前shell环境的Python版本来替换掉系统的版本，可以使用pyenv global 3.7.1  virtualenv使用  使用指定的Python版本创建虚拟环境pyenv virtualenv 3.7.1 myenv 启用虚拟环境 pyenv activate myenv 退出虚拟环境 source deactivate 进入项目目录自动启用虚拟环境，离开项目目录退出虚拟环境，需要在项目目录内 pyenv local myenv，会创建一个.python-version的文件，内容为虚拟环境的名字，则为myenv  done, 希望食用快乐~</description>
    </item>
    
    <item>
      <title>Python日期相关知识及处理</title>
      <link>https://sukikaka.cc/2018/11/27/python%E6%97%A5%E6%9C%9F%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E5%8F%8A%E5%A4%84%E7%90%86/</link>
      <pubDate>Tue, 27 Nov 2018 14:57:47 +0000</pubDate>
      
      <guid>https://sukikaka.cc/2018/11/27/python%E6%97%A5%E6%9C%9F%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E5%8F%8A%E5%A4%84%E7%90%86/</guid>
      <description>Python的日期实现/Linux发行版一般使用(tz database/Olson database)1
Python中的日期 一般使用pytz库来操作日期
django中的时区使用问题 https://docs.djangoproject.com/en/2.1/topics/i18n/timezones/
Time zone support is disabled by default. To enable it, set USE_TZ = True in your settings file. Time zone support uses pytz, which is installed when you install Django.
When support for time zones is enabled, Django stores datetime information in UTC in the database, uses time-zone-aware datetime objects internally, and translates them to the end user’s time zone in templates and forms.</description>
    </item>
    
    <item>
      <title>Ubnt ER-X pppoe定时重新拨号</title>
      <link>https://sukikaka.cc/2018/06/29/ubnt-er-x-pppoe%E5%AE%9A%E6%97%B6%E9%87%8D%E6%96%B0%E6%8B%A8%E5%8F%B7/</link>
      <pubDate>Fri, 29 Jun 2018 19:57:47 +0000</pubDate>
      
      <guid>https://sukikaka.cc/2018/06/29/ubnt-er-x-pppoe%E5%AE%9A%E6%97%B6%E9%87%8D%E6%96%B0%E6%8B%A8%E5%8F%B7/</guid>
      <description>为什么需要定时拨号？ 先来看一组数据
  从命令sudo cat /var/log/messages | grep local的输出结果来看，IP地址基本上每隔一定时间就发生变化。   从命令show interface pppoe pppoe0 log里面可以找出类似的日志，大意是电信给我们的路由器发了terminate命令，让我们断开连接。   结论也就是：
 广州电信，每次拨号维持时间为2875分钟/23小时55分钟，每次拨号维持这么长时间会被强行断网。 时间刚好是9点左右，每隔两天会减少5分钟，也就是。。。如果我周末这个时间点在家玩游戏，然后刚好碰上了，给我来个断网，呵呵
 解决方案 既然知道电信有这么蛋疼的设定，那么我们完全可以在不使用网络的情况下主动断开并重连来避开这个问题。
具体使用命令主要是下面两个：
 断开pppoe disconnect interface pppoe0 连接pppoe进行拨号 connect interface pppoe0
 那么如何定时去执行呢？
 ERX运行的系统基于Linux，那么第一个想到的方案就是使用crontab来跑定时任务，而在相当长的一段时间也是这样干的（路由器固件一般一两个月更新一个版本，除了更新版本，就没重启过路由了。。。） 直到，最近更新了路由器固件，crontab设置被清空了（这是固件设定，需要经过特定的方式做更新才能免于灾难）
 所以。。。最后写了个自定义的脚本，再使用系统授权的方式 task-scheduler 来执行这个脚本。
 编辑文件: sudo vi /config/scripts/pppoe-redial.sh  #!/bin/bash # 由于connect/disconnect命令都是alias，所以需要使用wrapper run=/opt/vyatta/bin/vyatta-op-cmd-wrapper $run disconnect interface pppoe0 sleep 10 $run connect interface pppoe0 保存～
 赋予执行权限 sudo chmod +x /config/scripts/pppoe-redial.</description>
    </item>
    
    <item>
      <title>Nginx配置的一些简单防护</title>
      <link>https://sukikaka.cc/2018/01/05/nginx%E9%85%8D%E7%BD%AE%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AE%80%E5%8D%95%E9%98%B2%E6%8A%A4/</link>
      <pubDate>Fri, 05 Jan 2018 16:57:47 +0000</pubDate>
      
      <guid>https://sukikaka.cc/2018/01/05/nginx%E9%85%8D%E7%BD%AE%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AE%80%E5%8D%95%E9%98%B2%E6%8A%A4/</guid>
      <description>拿到一台服务器之后，不管是用一键包还是正常软件包管理安装，一些简单的安全配置还是必要的。
验证server_name 首先需要验证server_name，因为IP和域名是一对多的关系，除非针对性攻击，否则一般是用IP+端口来尝试扫描服务器上面运行的网站和服务以找出一些通用的漏洞。（脚本小子最爱）
下面以test.sukikaka.com为域名来说明：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  server { listen 80; server_name test.sukikaka.com; # 假设我的vhost放这个位置  root /data/vhost/test_sukikaka_com; index index.php; gzip on; gzip_types text/plain application/xml; gzip_min_length 1000; gzip_proxied no-cache no-store private expired auth; access_log /var/log/nginx/test.</description>
    </item>
    
    <item>
      <title>网络基础-端口连通测试与排查</title>
      <link>https://sukikaka.cc/2017/10/30/%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80-%E7%AB%AF%E5%8F%A3%E8%BF%9E%E9%80%9A%E6%B5%8B%E8%AF%95%E4%B8%8E%E6%8E%92%E6%9F%A5/</link>
      <pubDate>Mon, 30 Oct 2017 16:57:47 +0000</pubDate>
      
      <guid>https://sukikaka.cc/2017/10/30/%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80-%E7%AB%AF%E5%8F%A3%E8%BF%9E%E9%80%9A%E6%B5%8B%E8%AF%95%E4%B8%8E%E6%8E%92%E6%9F%A5/</guid>
      <description>本文围绕端口讲解网络流量流向中可能出现的各种问题，水平有限，仅当入门篇。
访问端：怎么确认目标设备对应端口已经开启 常规方法：
 tcpping 端口open状态 telnet 端口可连接 其他tcp方案 本地端口没有被运营商or其他工具封锁，比如邮件的25端口 如果以上外部方案都发现并不能连接到目标端口，该那么怎么排查问题   SSH登录目标主机 假设我们想了解为什么80端口没连通，先确认80端口是否正在服务  sudo netstat -anp | grep :80    从结果可以看出主机已经开启了80端口，且服务的程序是Nginx
 被访问端：如何确认有请求访问 以下假设访问端和被访问端使用公网访问。
  ifconfig找出公网流量交换的网卡，比如下图我的是eth0   监听网卡eth0上的80端口的流量 sudo tcpdump -i eth0 port 80
    开启监听   另外一台机器使用tcpping来访问tcpping 45.34.167.101 80   观察tcpdump结果    结果是连通的，可以清晰看到tcp3次握手的sequence code
 接下来使用sudo service nginx stop关停nginx的80端口，然后再次做tcpping    端口已经关闭了，tcpdump依然可以看到类似上面的tcp握手请求
 被访问端：怎么确认端口是可达的（未被封锁）   那么假设防火墙拦截对80端口的请求呢？我们使用iptables对INPUT的流量全部采取DROP处理 sudo iptables -A INPUT -p tcp --dport 80 -j DROP</description>
    </item>
    
    <item>
      <title>一种有趣的测试环境部署方式</title>
      <link>https://sukikaka.cc/2017/08/31/%E4%B8%80%E7%A7%8D%E6%9C%89%E8%B6%A3%E7%9A%84%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%E6%96%B9%E5%BC%8F/</link>
      <pubDate>Thu, 31 Aug 2017 14:57:47 +0000</pubDate>
      
      <guid>https://sukikaka.cc/2017/08/31/%E4%B8%80%E7%A7%8D%E6%9C%89%E8%B6%A3%E7%9A%84%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%E6%96%B9%E5%BC%8F/</guid>
      <description>大背景  说需求不讲背景就是耍流氓。 &amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash; by 一个被虐的码农
 那么，背景是这样的，公司现有的测试业务情况如实交代：
 局域网自建mongo数据库，用于业务的测试环境数据（IP：192.168.2.100，电信公网IP 200.201.202.203，标记为服务器A） 公网阿里云ECS(IP: 100.101.102.103，标记为服务器B），用于外网测试环境代码的运行，通过服务器A的公网IP来连接mongo数据库 阿里云DNS配置A解析记录 dev.xxx.com 100.101.102.103 在脱离公司的公网环境，需要能正常访问dev.xxx.com的服务  问题来了  运营人员抱怨各种测试服务反应很慢。噢？那么我们来研究下网络数据走向和对应的时间消耗咯
  运营人员使用测试服务-&amp;gt;DNS解析dev.xxx.com-&amp;gt;请求服务器B-&amp;gt;通过服务器A的公网IP连接到mongo数据库-&amp;gt;上传数据回服务器B-&amp;gt;返回数据给和服务器A同一个公网出口的App（哇，这链条长的很开心） 通过配置PHP fpm slowlog得知，发现实际上时间消耗都花在了mongo相关的连接上面了，为什么呢？？？  分析问题  我们用的电信家用宽带，100M下载带宽，上传也就那么4M，完全不能看啊，稍微查询一个大一点的数据集，传输时间够喝一壶了，而且这么4M带宽，还要服务于公司员工正常的上网需求，那么降低这里的上传带宽使用也是很有必要的。
 选定方案  so，找到问题了，光说有什么用，得有解决方案啊
  把数据库也扔到外网去，那么对整个公司局域网来说，主要消耗只有对公网服务器B的请求下行数据，然而mongo对硬件消耗有点大，作为一个测试环境来讲，升级硬件配置或者再开一台服务器难免有点资源浪费，退而求其次，合理利用局域网服务器做mongo服务才是正路 服务器A硬件配置是强于ECS好多倍的，不要浪费了，那么就在服务器A上面搞事吧 通过分析上面的请求路径，那么我们可以把服务器A的公网上传拦截掉，怎么拦截呢？从DNS上面动手，于是请求路径会变成：APP-&amp;gt;解析dev.xxx.com-&amp;gt;请求服务器A（192.168.2.100）-&amp;gt;服务器A的程序请求localhost的数据库-&amp;gt;返回数据给程序-&amp;gt;返回给同一个局域网的运营测试人员 这样一来，速度提升的有点可怕，运营人员再也不腰痛了  解决问题  既然有初步方案了，那么怎么解决？
  那么需要使用“提速”的运营人员，可以通过配置HOST来实现 dev.xxx.com 解析成 192.168.2.100，如果只有PC平台的产品，倒也不失为一种选择 移动设备怎么办？Android不root，iOS不root没法玩啊，除非这些测试机器允许以某种方式“模拟配置host”，比如Android读取sd卡某个文件，若定义了解析数据，则以解析结果为准，需要预埋代码，改起来也麻烦，一点也不优雅 移动设备实在没办法改呢？那我配置代理咯，代理设备请求到能改HOST的PC设备，也是麻烦 既然这么蛋疼，那我配置一个DNS服务器好了，一番搜索之后，unbound这个软件上场了，配置一个DNS服务器，使用标准端口53，将局域网所有需要”提速“的设备首选DNS改成192.168.2.100即可 本着优化应该对使用者透明的原则，把上面这个配置DNS的步骤也省了，直接用DHCP服务器返回192.168.2.100作为首选DNS  断一下网，重新连接，刷新页面，一切只如初见，那么美好~
题外话 有人说，为了性价比，透明解决问题，为何不把所有服务都放在局域网的服务器A上面，连买ECS的钱都省了。。。
 骚年，你还是太年轻
  电信运营商怎能允许家用宽带用来做服务器提供服务这种行为，那么谁购买他高贵的企业专线带宽呢？于是我们家用宽带的80端口、8080端口默认都是被封了。 就算运营商不搞事，国家要求所有IDC必须只对有域名备案信息的域名才能提供正常的服务，就算配置了解析，在访问到具体的IP的时候，也是一样不能正常访问你的业务，从这个角度来讲，电信运营商封锁这两个端口也算是为了规避备案问题。 改端口也不是不行，然而综合考虑，改端口方案导致各个业务都需要做额外的配置修改，还是买个ECS做外网测试业务简单粗暴  那么其实除了上面的DNS方案，还有没有其他方案？答案是有的，理论上通过配置路由表SNAT，把对服务器B（100.101.102.103）的流量请求转发到服务器A192.168.2.100，然而该方案似乎有点一刀切，不够灵活，还是留着DNS，需要这种访问链路优化的话，配置首选DNS服务器为192.168.2.100，不需要的时候或者想强行访问服务器B的逻辑，那么只需要配置其他公用DNS即可。
UPDATE 2017-09-05 由于在实际使用过程中（大概1个多月的持续时长），发现对于不甚了解原理的小伙伴来讲，有额外的理解成本，业务也准备上HTTPS访问，那么就又来搞事吧，于是改为下面的方式：</description>
    </item>
    
    <item>
      <title>Android应用开发技能图谱</title>
      <link>https://sukikaka.cc/2017/08/29/android%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E6%8A%80%E8%83%BD%E5%9B%BE%E8%B0%B1/</link>
      <pubDate>Tue, 29 Aug 2017 14:57:47 +0000</pubDate>
      
      <guid>https://sukikaka.cc/2017/08/29/android%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E6%8A%80%E8%83%BD%E5%9B%BE%E8%B0%B1/</guid>
      <description>工具链   编程语言
 Java/Kotlin C/C++(NDK方向，源码阅读) SQL(DB) HTML/JS(Hybrid/Web App)    操作系统
 Linux/macOS/Windows    IDE:
 Android Studio为主 Eclipse    网络调试
 代理请求劫持与分析、重放：Charles/Wireshark/Fiddler 接口请求：Postman    内存分析
 Eclipse MAT Plugin Android Studio Monitors LeakCanary    综合分析（CPU、Network、Memory、GPU)：
 Android Studio Monitors    Android Tools
 Method Tracer ui hierarchy viewer ui automator viewer draw9patch    代码管理</description>
    </item>
    
    <item>
      <title>PHP错误排查</title>
      <link>https://sukikaka.cc/2017/08/24/php%E9%94%99%E8%AF%AF%E6%8E%92%E6%9F%A5/</link>
      <pubDate>Thu, 24 Aug 2017 12:42:47 +0000</pubDate>
      
      <guid>https://sukikaka.cc/2017/08/24/php%E9%94%99%E8%AF%AF%E6%8E%92%E6%9F%A5/</guid>
      <description>服务器配置  工欲善其事必先利其器，如果都不知道什么时候可能会产生日志，不知道哪里能查到错误日志，那么谈何排查？
  启用PHP错误配置[PHP程序运行错误日志]: /etc/php/*/fpm/php.ini （以FPM为例，cli同理）  log_errors = On error_log = /tmp/php_errors.log  启用fpm errors[这个是FPM本身的错误日志，不是服务的PHP程序的错误日志]： /etc/php/*/fpm/php-fpm.ini  error_log = /var/log/php-fpm.log  启用FPM workers slowlog/errors: /etc/php//fpm/pool.d/.conf  ; 因为PHP程序是以fpm worker的形式运行的，所以要获得输出需要启用worker output catch_workers_output = yes ; PHP 程序代码慢查询日志，比如代码中连接了数据库做查询，当超过一定时间则增加一条slowlog slowlog = /var/log/$pool.log.slow ; 此处定义多长时间为慢查询，一般5s已经很丧心病狂了 request_slowlog_timeout = 5s 修改完之后，使用sudo php-fpm -t做测试，一般会有的错误是，错误日志指定的路径不对，或者没权限写入，修改成其他可以写入的路径即可
一些错误示例   FPM Slow log，该优化代码啦！！！   PHP Error，该修BUG啦！！！   NOTE  看了还不赶紧配置日志、看日志改代码的同学，你懂的。
 </description>
    </item>
    
    <item>
      <title>使用Gitlab Webhooks自动部署代码</title>
      <link>https://sukikaka.cc/2017/05/27/%E4%BD%BF%E7%94%A8gitlab-webhooks%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2%E4%BB%A3%E7%A0%81/</link>
      <pubDate>Sat, 27 May 2017 12:41:47 +0000</pubDate>
      
      <guid>https://sukikaka.cc/2017/05/27/%E4%BD%BF%E7%94%A8gitlab-webhooks%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2%E4%BB%A3%E7%A0%81/</guid>
      <description>为什么要用Webhooks来更新代码  服务端的代码，不希望直接在服务器上面做更改，需要有中央仓库做托管管理，也利于协作 某些情况下，不希望给开发人员服务器ssh登录权限 开发时，希望得到更快的上线部署速度，享受git commit &amp;amp; git push &amp;amp; refresh的快感  Webhooks部署时需要考虑的一些因素  现有github，gitlab，oschina等一些托管基本都支持Webhooks，原理都是利用git hooks来做的拓展 什么情况下需要更新代码？根据commit message？根据branch? 更新代码时的执行身份？由什么用户来执行git？  设置Linux服务器  前提：当前已经登录root用户或者具有sudo权限的用户 确认即将用于执行git命令的用户，假定我们新增一个用户名git，专门用于跑git命令，那么执行 sudo adduser git，并设置密码 接下来，将git用户添加到sudo组：sudo adduser git sudo[此步骤非必须] 假定项目代码放在/www下面，且Owner是git，那么执行sudo mkdir /www &amp;amp;&amp;amp; sudo chown -R git:git /www 由于我们的Webhooks代码是用Nginx + PHP-FPM部署的，那么确认下PHP脚本的运行用户情况：ps aux | grep php-fpm， 确认www-data为我们的运行用户  将www-data加到git用户组：sudo usermod -aG git www-data 给www-data用户不需要密码就能切换到git用户，并且用git用户的身份执行/usr/bin/git命令，修改sudoers：sudo vim /etc/sudoers，添加一行配置：www-data ALL=(git) NOPASSWD: /usr/bin/git 允许同组用户新增文件时继承原有文件夹权限位：sudo chmod -R g+s /www[此步骤非必须] 由于我们希望无密码自动拉取代码，那么gitlab代码也是使用ssh方式来配置连接方式的，且hooks被触发时是通过www-data切换成git用户来执行/usr/bin/git命令，那么实际上git pull等命令使用的SSH key是git用户的SSH key，确保已经将git用户的/home/git/.ssh/id_rsa.pub文件的内容设置到gitlab项目中  实现Webhooks项目的代码   请参考gitlab-php-webhooks，具体逻辑请看代码注释</description>
    </item>
    
    <item>
      <title>打造基于Docker的Ubuntu 14.04 &#43; PHP-FPM &#43; Nginx运行环境</title>
      <link>https://sukikaka.cc/2017/05/25/%E6%89%93%E9%80%A0%E5%9F%BA%E4%BA%8Edocker%E7%9A%84ubuntu-14.04-php-fpm-nginx%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83/</link>
      <pubDate>Thu, 25 May 2017 16:41:50 +0000</pubDate>
      
      <guid>https://sukikaka.cc/2017/05/25/%E6%89%93%E9%80%A0%E5%9F%BA%E4%BA%8Edocker%E7%9A%84ubuntu-14.04-php-fpm-nginx%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83/</guid>
      <description>准备工作  安装docker、docker-compose 更改docker镜像源地址，加速访问  创建Dockerfile  在用户目录下创建docker项目文件夹  $ mkdir -p ~/docker &amp;amp;&amp;amp; cd ~/docker 创建Dockerfile  $ vim Dockerfile 由于我们是基于Ubuntu14.04做的镜像，所以定义好官方Ubuntu地址即可，在Dockerfile插入:FROM ubuntu:trusty，保存Dockerfile，然后运行docker build -t ubuntu:14.04-php-nginx .，如果你是第一次运行，需要从上面修改的docker源拉取ubuntu的镜像，会比较久。   我们用docker images来看结果，会有两个镜像，一个是拉下来的ubuntu:trusty，一个是我们定制的镜像: ubuntu:14.04-php-nginx   现在我们已经拥有一个本地image，使用交互模式启动容器准备进行定制 docker run -t -i ubuntu:14.04-php-nginx /bin/bash   把它当成一台装了Ubuntu的虚拟机，该怎么样怎么样，我们准备安装PHP-FPM和Nginx及一些PHP扩展，那么正常命令是这样的：(容器以root用户登录，且默认没有sudo命令，则不需要sudo)  apt-get update apt-get install -y nginx nginx php5 php5-fpm php-pear php5-dev php5-redis php5-gd php5-curl php5-mcrypt imagemagick php5-imagick supervisor pecl install mongo echo &#39;extension=mongo.so&#39; &amp;gt; /etc/php5/mods-available/mongo.ini ln -s /etc/php5/mods-available/mongo.</description>
    </item>
    
  </channel>
</rss>
